{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fe9588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40570148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory path: c:\\Users\\gorkemozkan\\Desktop\\gorkDrive\\finnews-insights\\data\n",
      "Data directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Get the current file's directory (src folder)\n",
    "current_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "\n",
    "# Define data directory (one level up from src, then into data)\n",
    "DATA_DIR = current_dir.parent / 'data'\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory path: {DATA_DIR}\")\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8235eaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to c:\\Users\\gorkemozkan\\Desktop\\gorkDrive\\finnews-insights\\data\\combined_train_data.xlsx\n",
      "Total number of rows: 59924\n",
      "\n",
      "First few rows of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[People, start, their, own, businesses, for, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[But, a, chance, to, fill, out, sales, -, tax,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[Red, tape, is, the, bugaboo, of, small, busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Ironically, ,, the, person, who, wants, to, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Yet, every, business, owner, has, to, face, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "2                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [People, start, their, own, businesses, for, m...  \n",
       "1  [But, a, chance, to, fill, out, sales, -, tax,...  \n",
       "2  [Red, tape, is, the, bugaboo, of, small, busin...  \n",
       "3  [Ironically, ,, the, person, who, wants, to, r...  \n",
       "4  [Yet, every, business, owner, has, to, face, t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to read and combine JSON files\n",
    "def combine_json_files(json_files):\n",
    "    all_data = []\n",
    "    \n",
    "    for file_name in json_files:\n",
    "        file_path = DATA_DIR / file_name\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line.strip())\n",
    "                    if isinstance(data, list):\n",
    "                        all_data.extend(data)\n",
    "                    else:\n",
    "                        all_data.append(data)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error in {file_name}, line: {line[:50]}...\")\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Process training data\n",
    "train_files = ['train00.json', 'train01.json', 'train02.json', 'train03.json']\n",
    "df_train = combine_json_files(train_files)\n",
    "\n",
    "# Save to Excel\n",
    "output_file = DATA_DIR / 'combined_train_data.xlsx'\n",
    "df_train.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {output_file}\")\n",
    "print(f\"Total number of rows: {len(df_train)}\")\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9244edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to c:\\Users\\gorkemozkan\\Desktop\\gorkDrive\\finnews-insights\\data\\combined_test_data.xlsx\n",
      "Total number of rows: 8262\n",
      "\n",
      "First few rows of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, ...</td>\n",
       "      <td>[The, following, were, among, Friday, 's, offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[11, 12, 12, 12]</td>\n",
       "      <td>[Dow, Chemical, Co., --]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[16, 17, 17, 0, 13, 14, 0, 0, 0, 2, 3, 3, 3, 0...</td>\n",
       "      <td>[$, 150, million, of, 8.55, %, senior, notes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, ...</td>\n",
       "      <td>[The, issue, ,, which, is, puttable, back, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 11, 12, 12, 12, 12, 0, 0...</td>\n",
       "      <td>[Rated, single, -, A, -, 1, by, Moody, 's, Inv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0  [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, ...   \n",
       "1                                   [11, 12, 12, 12]   \n",
       "2  [16, 17, 17, 0, 13, 14, 0, 0, 0, 2, 3, 3, 3, 0...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, ...   \n",
       "4  [0, 0, 0, 0, 0, 1, 0, 11, 12, 12, 12, 12, 0, 0...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [The, following, were, among, Friday, 's, offe...  \n",
       "1                           [Dow, Chemical, Co., --]  \n",
       "2  [$, 150, million, of, 8.55, %, senior, notes, ...  \n",
       "3  [The, issue, ,, which, is, puttable, back, to,...  \n",
       "4  [Rated, single, -, A, -, 1, by, Moody, 's, Inv...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process test data\n",
    "test_files = ['test.json']\n",
    "df_test = combine_json_files(test_files)\n",
    "\n",
    "# Save to Excel\n",
    "output_file = DATA_DIR / 'combined_test_data.xlsx'\n",
    "df_test.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {output_file}\")\n",
    "print(f\"Total number of rows: {len(df_test)}\")\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6fbc3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to c:\\Users\\gorkemozkan\\Desktop\\gorkDrive\\finnews-insights\\data\\combined_valid_data.xlsx\n",
      "Total number of rows: 8528\n",
      "\n",
      "First few rows of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 6, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[A, Russian, diver, has, found, the, bodies, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[The, diver, entered, the, sub, after, a, Russ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[The, drilling, and, cutting, effort, took, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[11, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[Navy, officials, do, not, expect, that, all, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11, 12, 12, 12, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0,...</td>\n",
       "      <td>[The, Balkan, Stability, Pact, has, admitted, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0  [0, 6, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0, 0, ...   \n",
       "2                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3           [11, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "4  [11, 12, 12, 12, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0,...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [A, Russian, diver, has, found, the, bodies, o...  \n",
       "1  [The, diver, entered, the, sub, after, a, Russ...  \n",
       "2  [The, drilling, and, cutting, effort, took, se...  \n",
       "3  [Navy, officials, do, not, expect, that, all, ...  \n",
       "4  [The, Balkan, Stability, Pact, has, admitted, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process validation data\n",
    "valid_files = ['valid.json']\n",
    "df_valid = combine_json_files(valid_files)\n",
    "\n",
    "# Save to Excel\n",
    "output_file = DATA_DIR / 'combined_valid_data.xlsx'\n",
    "df_valid.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {output_file}\")\n",
    "print(f\"Total number of rows: {len(df_valid)}\")\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "display(df_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26968dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have been updated and saved.\n",
      "\n",
      "Sample rows from training dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>['People', 'start', 'their', 'own', 'businesse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>['But', 'a', 'chance', 'to', 'fill', 'out', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>['Red', 'tape', 'is', 'the', 'bugaboo', 'of', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['Ironically', ',', 'the', 'person', 'who', 'w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['Yet', 'every', 'business', 'owner', 'has', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['People', 'start', 'their', 'own', 'businesse...  \n",
       "1  ['But', 'a', 'chance', 'to', 'fill', 'out', 's...  \n",
       "2  ['Red', 'tape', 'is', 'the', 'bugaboo', 'of', ...  \n",
       "3  ['Ironically', ',', 'the', 'person', 'who', 'w...  \n",
       "4  ['Yet', 'every', 'business', 'owner', 'has', '...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique labels remaining in the training dataset after update:\n",
      "[0, 2, 3, 4, 5, 11, 12, 13, 14, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "# Function to convert string representations of lists to actual lists\n",
    "def convert_string_to_list(string_list):\n",
    "    try:\n",
    "        return ast.literal_eval(string_list)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Read Excel files\n",
    "df_train = pd.read_excel(DATA_DIR / 'combined_train_data.xlsx')\n",
    "df_test = pd.read_excel(DATA_DIR / 'combined_test_data.xlsx')\n",
    "df_valid = pd.read_excel(DATA_DIR / 'combined_valid_data.xlsx')\n",
    "\n",
    "# Convert string lists to actual lists for each dataset\n",
    "for df in [df_train, df_test, df_valid]:\n",
    "    df['tags'] = df['tags'].apply(convert_string_to_list)\n",
    "\n",
    "# Labels to be converted to zero\n",
    "labels_to_zero = [1, 6, 7, 8, 9, 10, 15, 18, 19, 20, 21, 22, 23, 24, 25, \n",
    "                 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n",
    "\n",
    "# Function to update tags\n",
    "def update_tags(tags_list):\n",
    "    return [0 if tag in labels_to_zero else tag for tag in tags_list]\n",
    "\n",
    "# Update datasets\n",
    "for df in [df_train, df_test, df_valid]:\n",
    "    df['tags'] = df['tags'].apply(update_tags)\n",
    "\n",
    "# Save updated datasets\n",
    "df_train.to_excel(DATA_DIR / 'updated_train_data.xlsx', index=False)\n",
    "df_test.to_excel(DATA_DIR / 'updated_test_data.xlsx', index=False)\n",
    "df_valid.to_excel(DATA_DIR / 'updated_valid_data.xlsx', index=False)\n",
    "\n",
    "print(\"Datasets have been updated and saved.\")\n",
    "print(\"\\nSample rows from training dataset:\")\n",
    "display(df_train.head())\n",
    "\n",
    "# Check unique labels distribution\n",
    "print(\"\\nUnique labels remaining in the training dataset after update:\")\n",
    "unique_tags = set()\n",
    "for tags in df_train['tags']:\n",
    "    unique_tags.update(tags)\n",
    "print(sorted(list(unique_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25f4b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution after update:\n",
      "New label values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "New label system saved to label.json\n",
      "\n",
      "Label mappings:\n",
      "O: 0 -> 0\n",
      "B-DATE: 2 -> 1\n",
      "I-DATE: 3 -> 2\n",
      "B-PERSON: 4 -> 3\n",
      "I-PERSON: 5 -> 4\n",
      "B-ORG: 11 -> 5\n",
      "I-ORG: 12 -> 6\n",
      "B-PERCENT: 13 -> 7\n",
      "I-PERCENT: 14 -> 8\n",
      "B-MONEY: 16 -> 9\n",
      "I-MONEY: 17 -> 10\n",
      "\n",
      "New label system saved to label.json\n",
      "\n",
      "Label mappings:\n",
      "O: 0 -> 0\n",
      "B-DATE: 2 -> 1\n",
      "I-DATE: 3 -> 2\n",
      "B-PERSON: 4 -> 3\n",
      "I-PERSON: 5 -> 4\n",
      "B-ORG: 11 -> 5\n",
      "I-ORG: 12 -> 6\n",
      "B-PERCENT: 13 -> 7\n",
      "I-PERCENT: 14 -> 8\n",
      "B-MONEY: 16 -> 9\n",
      "I-MONEY: 17 -> 10\n",
      "\n",
      "Updated datasets have been saved.\n",
      "\n",
      "Updated datasets have been saved.\n"
     ]
    }
   ],
   "source": [
    "# Define label mapping for renumbering (Old -> New)\n",
    "label_mapping = {\n",
    "    0: 0,    # Keep O label as 0\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "    11: 5,\n",
    "    12: 6,\n",
    "    13: 7,\n",
    "    14: 8,\n",
    "    16: 9,\n",
    "    17: 10\n",
    "}\n",
    "\n",
    "# Function to update label numbers\n",
    "def update_label_numbers(tags_list):\n",
    "    return [label_mapping[tag] for tag in tags_list]\n",
    "\n",
    "# Update labels in each dataset\n",
    "for df in [df_train, df_test, df_valid]:\n",
    "    df['tags'] = df['tags'].apply(update_label_numbers)\n",
    "\n",
    "# Check updated label distribution\n",
    "print(\"Label distribution after update:\")\n",
    "unique_tags = set()\n",
    "for tags in df_train['tags']:\n",
    "    unique_tags.update(tags)\n",
    "print(\"New label values:\", sorted(list(unique_tags)))\n",
    "\n",
    "# Original label definitions\n",
    "original_labels = {\n",
    "    \"O\": 0,\n",
    "    \"B-DATE\": 2,\n",
    "    \"I-DATE\": 3,\n",
    "    \"B-PERSON\": 4,\n",
    "    \"I-PERSON\": 5,\n",
    "    \"B-ORG\": 11,\n",
    "    \"I-ORG\": 12,\n",
    "    \"B-PERCENT\": 13,\n",
    "    \"I-PERCENT\": 14,\n",
    "    \"B-MONEY\": 16,\n",
    "    \"I-MONEY\": 17\n",
    "}\n",
    "\n",
    "# Create new label system\n",
    "new_labels = {key: label_mapping[value] for key, value in original_labels.items()}\n",
    "\n",
    "# Save to label.json\n",
    "with open(DATA_DIR / 'label.json', 'w') as f:\n",
    "    json.dump(new_labels, f, indent=4)\n",
    "\n",
    "print(\"\\nNew label system saved to label.json\")\n",
    "print(\"\\nLabel mappings:\")\n",
    "for old_label, old_id in original_labels.items():\n",
    "    print(f\"{old_label}: {old_id} -> {label_mapping[old_id]}\")\n",
    "\n",
    "# Save updated datasets\n",
    "df_train.to_excel(DATA_DIR / 'updated_train_data.xlsx', index=False)\n",
    "df_test.to_excel(DATA_DIR / 'updated_test_data.xlsx', index=False)\n",
    "df_valid.to_excel(DATA_DIR / 'updated_valid_data.xlsx', index=False)\n",
    "\n",
    "print(\"\\nUpdated datasets have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b588a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset validations:\n",
      "\n",
      "1. Dataset dimensions:\n",
      "Train: 59924 samples\n",
      "Valid: 8528 samples\n",
      "Test: 8262 samples\n",
      "\n",
      "2. Check token and tag count alignment in each sample:\n",
      "\n",
      "Mismatch in train, sample 0:\n",
      "Number of tokens: 80\n",
      "Number of tags: 9\n",
      "Tokens: ['People', 'start', 'their', 'own', 'businesses', 'for', 'many', 'reasons', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in train, sample 1:\n",
      "Number of tokens: 117\n",
      "Number of tags: 16\n",
      "Tokens: ['But', 'a', 'chance', 'to', 'fill', 'out', 'sales', '-', 'tax', 'records', 'is', 'rarely', 'one', 'of', 'them', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in train, sample 2:\n",
      "Number of tokens: 71\n",
      "Number of tags: 9\n",
      "Tokens: ['Red', 'tape', 'is', 'the', 'bugaboo', 'of', 'small', 'business', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in valid, sample 0:\n",
      "Number of tokens: 221\n",
      "Number of tags: 27\n",
      "Tokens: ['A', 'Russian', 'diver', 'has', 'found', 'the', 'bodies', 'of', 'three', 'of', 'the', '118', 'sailors', 'who', 'were', 'killed', 'when', 'the', 'nuclear', 'submarine', 'Kursk', 'sank', 'in', 'the', 'Barents', 'Sea', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in valid, sample 1:\n",
      "Number of tokens: 206\n",
      "Number of tags: 25\n",
      "Tokens: ['The', 'diver', 'entered', 'the', 'sub', 'after', 'a', 'Russian', 'and', 'Norwegian', 'recovery', 'team', 'cut', 'a', 'hole', 'wide', 'enough', 'for', 'him', 'to', 'enter', 'a', 'rear', 'compartment', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in valid, sample 2:\n",
      "Number of tokens: 79\n",
      "Number of tags: 9\n",
      "Tokens: ['The', 'drilling', 'and', 'cutting', 'effort', 'took', 'several', 'days', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in test, sample 0:\n",
      "Number of tokens: 282\n",
      "Number of tags: 32\n",
      "Tokens: ['The', 'following', 'were', 'among', 'Friday', \"'s\", 'offerings', 'and', 'pricings', 'in', 'the', 'U.S.', 'and', 'non-U.S.', 'capital', 'markets', ',', 'with', 'terms', 'and', 'syndicate', 'manager', ',', 'as', 'compiled', 'by', 'Dow', 'Jones', 'Capital', 'Markets', 'Report', ':']\n",
      "Tags: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 0]\n",
      "\n",
      "Mismatch in test, sample 1:\n",
      "Number of tokens: 32\n",
      "Number of tags: 4\n",
      "Tokens: ['Dow', 'Chemical', 'Co.', '--']\n",
      "Tags: [5, 6, 6, 6]\n",
      "\n",
      "Mismatch in test, sample 2:\n",
      "Number of tokens: 128\n",
      "Number of tags: 18\n",
      "Tokens: ['$', '150', 'million', 'of', '8.55', '%', 'senior', 'notes', 'due', 'Oct.', '15', ',', '2009', ',', 'priced', 'at', 'par', '.']\n",
      "Tags: [9, 10, 10, 0, 7, 8, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in valid, sample 0:\n",
      "Number of tokens: 221\n",
      "Number of tags: 27\n",
      "Tokens: ['A', 'Russian', 'diver', 'has', 'found', 'the', 'bodies', 'of', 'three', 'of', 'the', '118', 'sailors', 'who', 'were', 'killed', 'when', 'the', 'nuclear', 'submarine', 'Kursk', 'sank', 'in', 'the', 'Barents', 'Sea', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in valid, sample 1:\n",
      "Number of tokens: 206\n",
      "Number of tags: 25\n",
      "Tokens: ['The', 'diver', 'entered', 'the', 'sub', 'after', 'a', 'Russian', 'and', 'Norwegian', 'recovery', 'team', 'cut', 'a', 'hole', 'wide', 'enough', 'for', 'him', 'to', 'enter', 'a', 'rear', 'compartment', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in valid, sample 2:\n",
      "Number of tokens: 79\n",
      "Number of tags: 9\n",
      "Tokens: ['The', 'drilling', 'and', 'cutting', 'effort', 'took', 'several', 'days', '.']\n",
      "Tags: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Mismatch in test, sample 0:\n",
      "Number of tokens: 282\n",
      "Number of tags: 32\n",
      "Tokens: ['The', 'following', 'were', 'among', 'Friday', \"'s\", 'offerings', 'and', 'pricings', 'in', 'the', 'U.S.', 'and', 'non-U.S.', 'capital', 'markets', ',', 'with', 'terms', 'and', 'syndicate', 'manager', ',', 'as', 'compiled', 'by', 'Dow', 'Jones', 'Capital', 'Markets', 'Report', ':']\n",
      "Tags: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 0]\n",
      "\n",
      "Mismatch in test, sample 1:\n",
      "Number of tokens: 32\n",
      "Number of tags: 4\n",
      "Tokens: ['Dow', 'Chemical', 'Co.', '--']\n",
      "Tags: [5, 6, 6, 6]\n",
      "\n",
      "Mismatch in test, sample 2:\n",
      "Number of tokens: 128\n",
      "Number of tags: 18\n",
      "Tokens: ['$', '150', 'million', 'of', '8.55', '%', 'senior', 'notes', 'due', 'Oct.', '15', ',', '2009', ',', 'priced', 'at', 'par', '.']\n",
      "Tags: [9, 10, 10, 0, 7, 8, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0]\n",
      "\n",
      "Total number of mismatches:\n",
      "Train: 59924\n",
      "Valid: 8528\n",
      "Test: 8262\n",
      "\n",
      "3. Check label distribution:\n",
      "\n",
      "Label distribution in train dataset:\n",
      "O (ID: 0): 994961 occurrences\n",
      "B-DATE (ID: 1): 10922 occurrences\n",
      "I-DATE (ID: 2): 13333 occurrences\n",
      "B-PERSON (ID: 3): 15429 occurrences\n",
      "I-PERSON (ID: 4): 11147 occurrences\n",
      "B-ORG (ID: 5): 12820 occurrences\n",
      "I-ORG (ID: 6): 18246 occurrences\n",
      "B-PERCENT (ID: 7): 1763 occurrences\n",
      "I-PERCENT (ID: 8): 2498 occurrences\n",
      "B-MONEY (ID: 9): 2411 occurrences\n",
      "I-MONEY (ID: 10): 4912 occurrences\n",
      "\n",
      "Label distribution in valid dataset:\n",
      "O (ID: 0): 135618 occurrences\n",
      "B-DATE (ID: 1): 1507 occurrences\n",
      "I-DATE (ID: 2): 1809 occurrences\n",
      "B-PERSON (ID: 3): 2020 occurrences\n",
      "I-PERSON (ID: 4): 1395 occurrences\n",
      "B-ORG (ID: 5): 1740 occurrences\n",
      "I-ORG (ID: 6): 2336 occurrences\n",
      "B-PERCENT (ID: 7): 177 occurrences\n",
      "I-PERCENT (ID: 8): 258 occurrences\n",
      "B-MONEY (ID: 9): 271 occurrences\n",
      "I-MONEY (ID: 10): 587 occurrences\n",
      "\n",
      "Label distribution in test dataset:\n",
      "O (ID: 0): 139641 occurrences\n",
      "B-DATE (ID: 1): 1602 occurrences\n",
      "I-DATE (ID: 2): 2011 occurrences\n",
      "B-PERSON (ID: 3): 1988 occurrences\n",
      "I-PERSON (ID: 4): 1412 occurrences\n",
      "B-ORG (ID: 5): 1795 occurrences\n",
      "I-ORG (ID: 6): 2406 occurrences\n",
      "B-PERCENT (ID: 7): 349 occurrences\n",
      "I-PERCENT (ID: 8): 523 occurrences\n",
      "B-MONEY (ID: 9): 313 occurrences\n",
      "I-MONEY (ID: 10): 683 occurrences\n",
      "\n",
      "Total number of mismatches:\n",
      "Train: 59924\n",
      "Valid: 8528\n",
      "Test: 8262\n",
      "\n",
      "3. Check label distribution:\n",
      "\n",
      "Label distribution in train dataset:\n",
      "O (ID: 0): 994961 occurrences\n",
      "B-DATE (ID: 1): 10922 occurrences\n",
      "I-DATE (ID: 2): 13333 occurrences\n",
      "B-PERSON (ID: 3): 15429 occurrences\n",
      "I-PERSON (ID: 4): 11147 occurrences\n",
      "B-ORG (ID: 5): 12820 occurrences\n",
      "I-ORG (ID: 6): 18246 occurrences\n",
      "B-PERCENT (ID: 7): 1763 occurrences\n",
      "I-PERCENT (ID: 8): 2498 occurrences\n",
      "B-MONEY (ID: 9): 2411 occurrences\n",
      "I-MONEY (ID: 10): 4912 occurrences\n",
      "\n",
      "Label distribution in valid dataset:\n",
      "O (ID: 0): 135618 occurrences\n",
      "B-DATE (ID: 1): 1507 occurrences\n",
      "I-DATE (ID: 2): 1809 occurrences\n",
      "B-PERSON (ID: 3): 2020 occurrences\n",
      "I-PERSON (ID: 4): 1395 occurrences\n",
      "B-ORG (ID: 5): 1740 occurrences\n",
      "I-ORG (ID: 6): 2336 occurrences\n",
      "B-PERCENT (ID: 7): 177 occurrences\n",
      "I-PERCENT (ID: 8): 258 occurrences\n",
      "B-MONEY (ID: 9): 271 occurrences\n",
      "I-MONEY (ID: 10): 587 occurrences\n",
      "\n",
      "Label distribution in test dataset:\n",
      "O (ID: 0): 139641 occurrences\n",
      "B-DATE (ID: 1): 1602 occurrences\n",
      "I-DATE (ID: 2): 2011 occurrences\n",
      "B-PERSON (ID: 3): 1988 occurrences\n",
      "I-PERSON (ID: 4): 1412 occurrences\n",
      "B-ORG (ID: 5): 1795 occurrences\n",
      "I-ORG (ID: 6): 2406 occurrences\n",
      "B-PERCENT (ID: 7): 349 occurrences\n",
      "I-PERCENT (ID: 8): 523 occurrences\n",
      "B-MONEY (ID: 9): 313 occurrences\n",
      "I-MONEY (ID: 10): 683 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Perform final checks\n",
    "print(\"Dataset validations:\")\n",
    "print(\"\\n1. Dataset dimensions:\")\n",
    "print(f\"Train: {len(df_train)} samples\")\n",
    "print(f\"Valid: {len(df_valid)} samples\")\n",
    "print(f\"Test: {len(df_test)} samples\")\n",
    "\n",
    "print(\"\\n2. Check token and tag count alignment in each sample:\")\n",
    "def check_token_tag_alignment(df, name):\n",
    "    mismatches = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if len(row['tokens']) != len(row['tags']):\n",
    "            mismatches += 1\n",
    "            if mismatches <= 3:  # Show first 3 mismatches\n",
    "                print(f\"\\nMismatch in {name}, sample {i}:\")\n",
    "                print(f\"Number of tokens: {len(row['tokens'])}\")\n",
    "                print(f\"Number of tags: {len(row['tags'])}\")\n",
    "                print(f\"Tokens: {row['tokens']}\")\n",
    "                print(f\"Tags: {row['tags']}\")\n",
    "    return mismatches\n",
    "\n",
    "train_mismatches = check_token_tag_alignment(df_train, \"train\")\n",
    "valid_mismatches = check_token_tag_alignment(df_valid, \"valid\")\n",
    "test_mismatches = check_token_tag_alignment(df_test, \"test\")\n",
    "\n",
    "print(f\"\\nTotal number of mismatches:\")\n",
    "print(f\"Train: {train_mismatches}\")\n",
    "print(f\"Valid: {valid_mismatches}\")\n",
    "print(f\"Test: {test_mismatches}\")\n",
    "\n",
    "print(\"\\n3. Check label distribution:\")\n",
    "def check_label_distribution(df, name):\n",
    "    all_tags = []\n",
    "    for tags in df['tags']:\n",
    "        all_tags.extend(tags)\n",
    "    \n",
    "    unique, counts = np.unique(all_tags, return_counts=True)\n",
    "    print(f\"\\nLabel distribution in {name} dataset:\")\n",
    "    for label, count in zip(unique, counts):\n",
    "        label_name = [k for k, v in new_labels.items() if v == label][0]\n",
    "        print(f\"{label_name} (ID: {label}): {count} occurrences\")\n",
    "\n",
    "# Check distribution for each dataset\n",
    "for df, name in [(df_train, 'train'), (df_valid, 'valid'), (df_test, 'test')]:\n",
    "    check_label_distribution(df, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e7b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Remove samples where all tags are 0:\n",
      "Before filtering:\n",
      "Train: 59924 samples\n",
      "Valid: 8528 samples\n",
      "Test: 8262 samples\n",
      "\n",
      "After filtering:\n",
      "Train: 23603 samples (removed 36321 samples)\n",
      "Valid: 3062 samples (removed 5466 samples)\n",
      "Test: 3239 samples (removed 5023 samples)\n",
      "\n",
      "Final datasets have been saved.\n",
      "\n",
      "5. Final label distribution after removing all-zero samples:\n",
      "\n",
      "Label distribution in train dataset:\n",
      "O (ID: 0): 499783 occurrences\n",
      "B-DATE (ID: 1): 10922 occurrences\n",
      "I-DATE (ID: 2): 13333 occurrences\n",
      "B-PERSON (ID: 3): 15429 occurrences\n",
      "I-PERSON (ID: 4): 11147 occurrences\n",
      "B-ORG (ID: 5): 12820 occurrences\n",
      "I-ORG (ID: 6): 18246 occurrences\n",
      "B-PERCENT (ID: 7): 1763 occurrences\n",
      "I-PERCENT (ID: 8): 2498 occurrences\n",
      "B-MONEY (ID: 9): 2411 occurrences\n",
      "I-MONEY (ID: 10): 4912 occurrences\n",
      "\n",
      "Label distribution in valid dataset:\n",
      "O (ID: 0): 63406 occurrences\n",
      "B-DATE (ID: 1): 1507 occurrences\n",
      "I-DATE (ID: 2): 1809 occurrences\n",
      "B-PERSON (ID: 3): 2020 occurrences\n",
      "I-PERSON (ID: 4): 1395 occurrences\n",
      "B-ORG (ID: 5): 1740 occurrences\n",
      "I-ORG (ID: 6): 2336 occurrences\n",
      "B-PERCENT (ID: 7): 177 occurrences\n",
      "I-PERCENT (ID: 8): 258 occurrences\n",
      "B-MONEY (ID: 9): 271 occurrences\n",
      "I-MONEY (ID: 10): 587 occurrences\n",
      "\n",
      "Label distribution in test dataset:\n",
      "O (ID: 0): 68294 occurrences\n",
      "B-DATE (ID: 1): 1602 occurrences\n",
      "I-DATE (ID: 2): 2011 occurrences\n",
      "B-PERSON (ID: 3): 1988 occurrences\n",
      "I-PERSON (ID: 4): 1412 occurrences\n",
      "B-ORG (ID: 5): 1795 occurrences\n",
      "I-ORG (ID: 6): 2406 occurrences\n",
      "B-PERCENT (ID: 7): 349 occurrences\n",
      "I-PERCENT (ID: 8): 523 occurrences\n",
      "B-MONEY (ID: 9): 313 occurrences\n",
      "I-MONEY (ID: 10): 683 occurrences\n",
      "\n",
      "Final datasets have been saved.\n",
      "\n",
      "5. Final label distribution after removing all-zero samples:\n",
      "\n",
      "Label distribution in train dataset:\n",
      "O (ID: 0): 499783 occurrences\n",
      "B-DATE (ID: 1): 10922 occurrences\n",
      "I-DATE (ID: 2): 13333 occurrences\n",
      "B-PERSON (ID: 3): 15429 occurrences\n",
      "I-PERSON (ID: 4): 11147 occurrences\n",
      "B-ORG (ID: 5): 12820 occurrences\n",
      "I-ORG (ID: 6): 18246 occurrences\n",
      "B-PERCENT (ID: 7): 1763 occurrences\n",
      "I-PERCENT (ID: 8): 2498 occurrences\n",
      "B-MONEY (ID: 9): 2411 occurrences\n",
      "I-MONEY (ID: 10): 4912 occurrences\n",
      "\n",
      "Label distribution in valid dataset:\n",
      "O (ID: 0): 63406 occurrences\n",
      "B-DATE (ID: 1): 1507 occurrences\n",
      "I-DATE (ID: 2): 1809 occurrences\n",
      "B-PERSON (ID: 3): 2020 occurrences\n",
      "I-PERSON (ID: 4): 1395 occurrences\n",
      "B-ORG (ID: 5): 1740 occurrences\n",
      "I-ORG (ID: 6): 2336 occurrences\n",
      "B-PERCENT (ID: 7): 177 occurrences\n",
      "I-PERCENT (ID: 8): 258 occurrences\n",
      "B-MONEY (ID: 9): 271 occurrences\n",
      "I-MONEY (ID: 10): 587 occurrences\n",
      "\n",
      "Label distribution in test dataset:\n",
      "O (ID: 0): 68294 occurrences\n",
      "B-DATE (ID: 1): 1602 occurrences\n",
      "I-DATE (ID: 2): 2011 occurrences\n",
      "B-PERSON (ID: 3): 1988 occurrences\n",
      "I-PERSON (ID: 4): 1412 occurrences\n",
      "B-ORG (ID: 5): 1795 occurrences\n",
      "I-ORG (ID: 6): 2406 occurrences\n",
      "B-PERCENT (ID: 7): 349 occurrences\n",
      "I-PERCENT (ID: 8): 523 occurrences\n",
      "B-MONEY (ID: 9): 313 occurrences\n",
      "I-MONEY (ID: 10): 683 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Function to remove samples where all tags are 0\n",
    "def remove_all_zero_samples(df):\n",
    "    # Check if all tags in a row are 0\n",
    "    mask = df['tags'].apply(lambda x: not all(tag == 0 for tag in x))\n",
    "    filtered_df = df[mask]\n",
    "    return filtered_df\n",
    "\n",
    "print(\"\\n4. Remove samples where all tags are 0:\")\n",
    "print(\"Before filtering:\")\n",
    "print(f\"Train: {len(df_train)} samples\")\n",
    "print(f\"Valid: {len(df_valid)} samples\")\n",
    "print(f\"Test: {len(df_test)} samples\")\n",
    "\n",
    "# Apply filtering to all datasets\n",
    "df_train_final = remove_all_zero_samples(df_train)\n",
    "df_valid_final = remove_all_zero_samples(df_valid)\n",
    "df_test_final = remove_all_zero_samples(df_test)\n",
    "\n",
    "print(\"\\nAfter filtering:\")\n",
    "print(f\"Train: {len(df_train_final)} samples (removed {len(df_train) - len(df_train_final)} samples)\")\n",
    "print(f\"Valid: {len(df_valid_final)} samples (removed {len(df_valid) - len(df_valid_final)} samples)\")\n",
    "print(f\"Test: {len(df_test_final)} samples (removed {len(df_test) - len(df_test_final)} samples)\")\n",
    "\n",
    "# Save final datasets\n",
    "df_train_final.to_excel(DATA_DIR / 'final_train_data.xlsx', index=False)\n",
    "df_valid_final.to_excel(DATA_DIR / 'final_valid_data.xlsx', index=False)\n",
    "df_test_final.to_excel(DATA_DIR / 'final_test_data.xlsx', index=False)\n",
    "\n",
    "print(\"\\nFinal datasets have been saved.\")\n",
    "\n",
    "# Check label distribution in final datasets\n",
    "print(\"\\n5. Final label distribution after removing all-zero samples:\")\n",
    "for df, name in [(df_train_final, 'train'), (df_valid_final, 'valid'), (df_test_final, 'test')]:\n",
    "    check_label_distribution(df, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff60749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
