{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad532c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForTokenClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df89fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory path: c:\\Users\\gorkemozkan\\Desktop\\gorkDrive\\finnews-insights\\data\n",
      "Data directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Get the current file's directory (src folder)\n",
    "current_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "\n",
    "# Define data directory (one level up from src, then into data)\n",
    "DATA_DIR = current_dir.parent / 'data'\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Data directory path: {DATA_DIR}\")\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac285091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "Train: 23603 samples\n",
      "Valid: 3062 samples\n",
      "Test: 3239 samples\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_excel(DATA_DIR / 'final_train_data.xlsx')\n",
    "df_valid = pd.read_excel(DATA_DIR / 'final_valid_data.xlsx')\n",
    "df_test = pd.read_excel(DATA_DIR / 'final_test_data.xlsx')\n",
    "\n",
    "# Convert string lists to actual lists\n",
    "def convert_string_to_list(string_list):\n",
    "    try:\n",
    "        return ast.literal_eval(string_list)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Convert string lists to actual lists for each dataset\n",
    "df_train['tokens'] = df_train['tokens'].apply(convert_string_to_list)\n",
    "df_train['tags'] = df_train['tags'].apply(convert_string_to_list)\n",
    "\n",
    "df_valid['tokens'] = df_valid['tokens'].apply(convert_string_to_list)\n",
    "df_valid['tags'] = df_valid['tags'].apply(convert_string_to_list)\n",
    "\n",
    "df_test['tokens'] = df_test['tokens'].apply(convert_string_to_list)\n",
    "df_test['tags'] = df_test['tags'].apply(convert_string_to_list)\n",
    "\n",
    "print(\"Dataset dimensions:\")\n",
    "print(f\"Train: {len(df_train)} samples\")\n",
    "print(f\"Valid: {len(df_valid)} samples\")\n",
    "print(f\"Test: {len(df_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d808a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label distribution\n",
    "def check_label_distribution(df, name):\n",
    "    all_tags = []\n",
    "    for tags in df['tags']:\n",
    "        all_tags.extend(tags)\n",
    "    unique, counts = np.unique(all_tags, return_counts=True)\n",
    "    total = sum(counts)\n",
    "    print(f\"\\nLabel distribution in {name} dataset:\")\n",
    "    for u, c in zip(unique, counts):\n",
    "        print(f\"Label {u}: {c} occurrences ({(c/total)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nLabel distribution after filtering:\")\n",
    "check_label_distribution(df_train, \"Train\")\n",
    "check_label_distribution(df_valid, \"Validation\")\n",
    "check_label_distribution(df_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021bfb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label mappings:\n",
      "O: 0\n",
      "B-DATE: 1\n",
      "I-DATE: 2\n",
      "B-PERSON: 3\n",
      "I-PERSON: 4\n",
      "B-ORG: 5\n",
      "I-ORG: 6\n",
      "B-PERCENT: 7\n",
      "I-PERCENT: 8\n",
      "B-MONEY: 9\n",
      "I-MONEY: 10\n"
     ]
    }
   ],
   "source": [
    "# Load label file and create label mappings\n",
    "with open(DATA_DIR / 'label.json', 'r') as f:\n",
    "    label_dict = json.load(f)\n",
    "\n",
    "# Create label2id and id2label dictionaries\n",
    "label2id = label_dict  # mappings from label.json\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "print(\"\\nLabel mappings:\")\n",
    "for label, idx in label2id.items():\n",
    "    print(f\"{label}: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ab4273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: bert-base-cased\n",
      "Total number of parameters: 107,728,139\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_checkpoint = \"bert-base-cased\"  # BERT model for English\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Load model and set number of classes\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {model_checkpoint}\")\n",
    "print(f\"Total number of parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d665347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 23603/23603 [00:01<00:00, 12327.96 examples/s]\n",
      "Map: 100%|██████████| 3062/3062 [00:00<00:00, 12770.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 23603\n",
      "Validation set size: 3062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper function to tokenize and align labels\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        \n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(int(label[word_idx]))\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "            \n",
    "        labels.append(label_ids)\n",
    "        \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Get tokens and labels from DataFrames\n",
    "train_sentences = df_train['tokens'].tolist()\n",
    "train_labels = df_train['tags'].tolist()\n",
    "valid_sentences = df_valid['tokens'].tolist()\n",
    "valid_labels = df_valid['tags'].tolist()\n",
    "\n",
    "# Convert data to datasets format\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"tokens\": train_sentences,\n",
    "    \"ner_tags\": train_labels\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"tokens\": valid_sentences,\n",
    "    \"ner_tags\": valid_labels\n",
    "})\n",
    "\n",
    "# Tokenize data\n",
    "train_tokenized = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "val_tokenized = val_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "print(\"Training set size:\", len(train_tokenized))\n",
    "print(\"Validation set size:\", len(val_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6509a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready, training can begin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gorkemozkan\\AppData\\Local\\Temp\\ipykernel_10732\\1472509854.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(DATA_DIR / \"results\"),  # Convert Path to string for training arguments\n",
    "    eval_strategy=\"epoch\",          # Evaluate at the end of each epoch\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,            \n",
    "    weight_decay=0.001,           \n",
    "    save_strategy=\"epoch\",        \n",
    "    logging_steps=50,           \n",
    "    load_best_model_at_end=True,   \n",
    "    metric_for_best_model=\"f1\",    \n",
    "    greater_is_better=True,       \n",
    "    save_total_limit=2,           \n",
    "    hub_strategy=\"end\",           \n",
    "    report_to=[\"none\"],          \n",
    "    warmup_steps=200,\n",
    "    fp16=True,                    \n",
    "    gradient_accumulation_steps=2,\n",
    "    label_smoothing_factor=0.1,\n",
    "    dataloader_num_workers=2,    \n",
    "    optim=\"adamw_torch\"         \n",
    ")\n",
    "\n",
    "# Set up data collator\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Define metric function for evaluation\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    # Flatten the predictions and labels\n",
    "    flat_predictions = [p for pred in true_predictions for p in pred]\n",
    "    flat_labels = [l for label in true_labels for l in label]\n",
    "    \n",
    "    # Calculate metrics using sklearn's classification_report\n",
    "    results = classification_report(flat_labels, flat_predictions, output_dict=True)\n",
    "    \n",
    "    # Return the metrics\n",
    "    return {\n",
    "        'precision': results['weighted avg']['precision'],\n",
    "        'recall': results['weighted avg']['recall'],\n",
    "        'f1': results['weighted avg']['f1-score'],\n",
    "        'accuracy': results['accuracy']\n",
    "    }\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"Trainer ready, training can begin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7511a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d403ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions = trainer.predict(val_tokenized)\n",
    "\n",
    "# Get predictions and true labels\n",
    "true_predictions = [\n",
    "    [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
    "    for pred, label in zip(predictions.predictions.argmax(-1), predictions.label_ids)\n",
    "]\n",
    "\n",
    "true_labels = [\n",
    "    [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
    "    for pred, label in zip(predictions.predictions.argmax(-1), predictions.label_ids)\n",
    "]\n",
    "\n",
    "# Create classification report\n",
    "report = classification_report(\n",
    "    [item for sublist in true_labels for item in sublist],\n",
    "    [item for sublist in true_predictions for item in sublist]\n",
    ")\n",
    "\n",
    "print(\"Model Evaluation Results:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(text, hardware='cpu'):\n",
    "    \"\"\"\n",
    "    Identifies entities in the text.\n",
    "    Args:\n",
    "        text (str): Text to process\n",
    "        hardware (str): Hardware to use - 'cpu' or 'gpu'\n",
    "    \"\"\"\n",
    "    # Device selection\n",
    "    device = 'cuda' if hardware.lower() == 'gpu' else 'cpu'\n",
    "    \n",
    "    # If GPU is selected but not available, warn and switch to CPU\n",
    "    if device == 'cuda' and not torch.cuda.is_available():\n",
    "        print(\"GPU not found, using CPU...\")\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # Move model to selected device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Split text into words\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Tokenize\n",
    "    # First do encoding\n",
    "    encoding = tokenizer(tokens, truncation=True, is_split_into_words=True, return_tensors=\"pt\")\n",
    "    word_ids = encoding.word_ids()\n",
    "    \n",
    "    # Move input tensors to selected device\n",
    "    inputs = {k: v.to(device) for k, v in encoding.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():  # No gradient calculation\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits.argmax(-1)\n",
    "    \n",
    "    # Convert predictions to labels\n",
    "    predicted_labels = []\n",
    "    for i, pred in enumerate(predictions[0]):\n",
    "        if word_ids[i] is not None:  # if not a special token\n",
    "            predicted_labels.append(id2label[pred.item()])\n",
    "    \n",
    "    # Visualize results\n",
    "    results = []\n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        if label != 'O':\n",
    "            results.append((token, label))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113497b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text\n",
    "test_text = \"Apple CEO Tim Cook introduced the new iPhone model at a conference held in San Francisco.\"\n",
    "\n",
    "# Test with selected hardware\n",
    "hardware = 'cpu'  # can be changed to 'gpu'\n",
    "print(f\"\\nTesting with {hardware.upper()}:\")\n",
    "\n",
    "# Make predictions\n",
    "results = predict_entities(test_text, hardware)\n",
    "\n",
    "# Show results\n",
    "print(\"\\nTest text:\", test_text)\n",
    "print(\"\\nFound entities:\")\n",
    "for token, label in results:\n",
    "    print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e187b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "output_dir = DATA_DIR / \"ner_model\"\n",
    "model.save_pretrained(str(output_dir))  # Convert Path to string for save_pretrained\n",
    "tokenizer.save_pretrained(str(output_dir))\n",
    "\n",
    "print(f\"Model and tokenizer saved to directory: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
