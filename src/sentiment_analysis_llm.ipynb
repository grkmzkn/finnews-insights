{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cd23194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Set the directory for NLTK data\\nnltk_data_dir = os.path.join(os.path.dirname(os.path.abspath(\\'__file__\\')), \\'nltk_data\\')\\nif not os.path.exists(nltk_data_dir):\\n    os.makedirs(nltk_data_dir)\\n\\n# Configure NLTK data directory\\nnltk.data.path.insert(0, nltk_data_dir)\\n\\n# Download required NLTK datasets\\nprint(\"Downloading NLTK datasets...\")\\nfor dataset in [\\'punkt\\', \\'stopwords\\', \\'wordnet\\', \\'omw-1.4\\']:\\n    print(f\"Downloading {dataset}...\")\\n    nltk.download(dataset, download_dir=nltk_data_dir, quiet=True)\\n    print(f\"{dataset} downloaded.\")\\n\\n# Verify downloaded datasets\\nprint(\"\\nVerifying NLTK datasets...\")\\ntry:\\n    # Test dataset usage\\n    word_tokenize(\"Test sentence\")\\n    stopwords.words(\\'english\\')\\n    lemmatizer = WordNetLemmatizer()\\n    lemmatizer.lemmatize(\"testing\")\\n    print(\"All NLTK datasets successfully loaded and tested.\")\\nexcept LookupError as e:\\n    print(f\"Error: {str(e)}\")\\n    print(\"An error occurred while loading NLTK datasets.\")\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NOTE: Run this section only once to download NLTK datasets\n",
    "# After running once successfully, you can comment out the section below\n",
    "\"\"\"\n",
    "# Set the directory for NLTK data\n",
    "nltk_data_dir = os.path.join(os.path.dirname(os.path.abspath('__file__')), 'nltk_data')\n",
    "if not os.path.exists(nltk_data_dir):\n",
    "    os.makedirs(nltk_data_dir)\n",
    "\n",
    "# Configure NLTK data directory\n",
    "nltk.data.path.insert(0, nltk_data_dir)\n",
    "\n",
    "# Download required NLTK datasets\n",
    "print(\"Downloading NLTK datasets...\")\n",
    "for dataset in ['punkt', 'stopwords', 'wordnet', 'omw-1.4']:\n",
    "    print(f\"Downloading {dataset}...\")\n",
    "    nltk.download(dataset, download_dir=nltk_data_dir, quiet=True)\n",
    "    print(f\"{dataset} downloaded.\")\n",
    "\n",
    "# Verify downloaded datasets\n",
    "print(\"\\nVerifying NLTK datasets...\")\n",
    "try:\n",
    "    # Test dataset usage\n",
    "    word_tokenize(\"Test sentence\")\n",
    "    stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizer.lemmatize(\"testing\")\n",
    "    print(\"All NLTK datasets successfully loaded and tested.\")\n",
    "except LookupError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"An error occurred while loading NLTK datasets.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfb37a",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fca744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: 5843\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence</td>\n",
       "      <td>Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                           Sentence  Sentiment\n",
       "1  The GeoSolutions technology will leverage Bene...   positive\n",
       "2  $ESI on lows, down $1.50 to $2.50 BK a real po...   negative\n",
       "3  For the last quarter of 2010 , Componenta 's n...   positive\n",
       "4  According to the Finnish-Russian Chamber of Co...    neutral"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/sentiment_data.csv', header=None, names=['text', 'sentiment'])\n",
    "\n",
    "print(\"Initial dataset size:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24e4bd",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Apply the same preprocessing steps as in sentiment_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca76815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and encoding: map sentiment labels directly to numeric values\n",
    "def encode_sentiment(s):\n",
    "    \"\"\"\n",
    "    Encode sentiment labels to numeric values for model training.\n",
    "    \n",
    "    Args:\n",
    "        s (str): Input sentiment label\n",
    "        \n",
    "    Returns:\n",
    "        int: Encoded sentiment value\n",
    "            - 2: negative\n",
    "            - 1: positive\n",
    "            - 0: neutral\n",
    "            - None: unknown values\n",
    "    \"\"\"\n",
    "    s = str(s).lower().strip()\n",
    "    if s in ['negative', 'neg', '-1']:\n",
    "        return 2  # negative -> 2\n",
    "    elif s in ['neutral', 'neu', '0']:\n",
    "        return 0  # neutral -> 0\n",
    "    elif s in ['positive', 'pos', '1']:\n",
    "        return 1  # positive -> 1\n",
    "    else:\n",
    "        return None  # for unknown values\n",
    "\n",
    "# Apply encoding\n",
    "df['sentiment_encoded'] = df['sentiment'].apply(encode_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7033bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 1 records with unknown sentiment values\n",
      "Dataset size after removing unknown labels: 5842\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with unknown sentiment (None values)\n",
    "unknown_count = df['sentiment_encoded'].isna().sum()\n",
    "if unknown_count > 0:\n",
    "    print(f\"Removing {unknown_count} records with unknown sentiment values\")\n",
    "    df = df.dropna(subset=['sentiment_encoded'])\n",
    "\n",
    "print(\"Dataset size after removing unknown labels:\", len(df))\n",
    "\n",
    "# Convert encoded values to int type\n",
    "df['sentiment_encoded'] = df['sentiment_encoded'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d8bdf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 520 duplicate records\n",
      "Dataset size after removing duplicates: 5322\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate entries based on text\n",
    "duplicate_count = df.duplicated(subset=['text']).sum()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Removing {duplicate_count} duplicate records\")\n",
    "    df = df.drop_duplicates(subset=['text'], keep='first')\n",
    "    print(\"Dataset size after removing duplicates:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aa61e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Label Mapping:\n",
      "negative -> 2\n",
      "neutral -> 0\n",
      "positive -> 1\n"
     ]
    }
   ],
   "source": [
    "# Store the mapping for reference\n",
    "sentiment_mapping = {\n",
    "    'negative': 2,\n",
    "    'neutral': 0,\n",
    "    'positive': 1\n",
    "}\n",
    "print(\"\\nSentiment Label Mapping:\")\n",
    "for sentiment, code in sentiment_mapping.items():\n",
    "    print(f\"{sentiment} -> {code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ff82d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of sentiment classes:\n",
      "sentiment_encoded\n",
      "neutral     2878\n",
      "positive    1852\n",
      "negative     592\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the distribution of sentiment classes\n",
    "print(\"Distribution of sentiment classes:\")\n",
    "sentiment_counts_encoded = df['sentiment_encoded'].map({2: 'negative', 0: 'neutral', 1: 'positive'}).value_counts()\n",
    "print(sentiment_counts_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9383fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment  \\\n",
      "1  The GeoSolutions technology will leverage Bene...  positive   \n",
      "2  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative   \n",
      "3  For the last quarter of 2010 , Componenta 's n...  positive   \n",
      "4  According to the Finnish-Russian Chamber of Co...   neutral   \n",
      "5  The Swedish buyout firm has sold its remaining...   neutral   \n",
      "\n",
      "   sentiment_encoded  \n",
      "1                  1  \n",
      "2                  2  \n",
      "3                  1  \n",
      "4                  0  \n",
      "5                  0  \n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of the cleaned dataset\n",
    "print(df[['text', 'sentiment', 'sentiment_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7906582",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "1. Convert to lowercase\n",
    "2. Remove punctuation\n",
    "3. Remove stop words\n",
    "4. Apply lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f954d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      processed_text\n",
      "1  geosolutions technology leverage benefon gps s...\n",
      "2                               low real possibility\n",
      "3  last quarter componenta net sale double eur eu...\n",
      "4  accord finnish russian chamber commerce major ...\n",
      "5  swedish buyout firm sell remain percent stake ...\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text data by applying various cleaning and normalization steps.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Raw input text to be preprocessed\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned and normalized text with the following transformations:\n",
    "            - Converted to lowercase\n",
    "            - Removed URLs, email addresses, stock symbols\n",
    "            - Removed percentages and currency amounts\n",
    "            - Removed special characters and numbers\n",
    "            - Tokenized and removed stop words\n",
    "            - Applied lemmatization\n",
    "            - Removed short words (length < 3)\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove stock symbols (e.g., $AAPL, $GOOG)\n",
    "    text = re.sub(r'\\$\\w+', '', text)\n",
    "    \n",
    "    # Remove numbers with % (percentage)\n",
    "    text = re.sub(r'\\d+%', '', text)\n",
    "    \n",
    "    # Remove currency symbols and amounts (e.g., $123.45, €100, £50)\n",
    "    text = re.sub(r'[$€£¥]\\d+(?:\\.\\d{2})?|\\d+(?:\\.\\d{2})?[$€£¥]', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    # Keep alphabets and spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatization with pos tagging for better accuracy\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token, pos='v') for token in tokens]  # First try as verb\n",
    "    tokens = [lemmatizer.lemmatize(token, pos='n') for token in tokens]  # Then as noun\n",
    "    \n",
    "    # Remove short words (length < 3)\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess texts in the dataset\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "print(df[['processed_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff3cd3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 5322\n",
      "Filtered dataset size: 5080\n",
      "Number of removed examples: 242\n",
      "                                       Original Text  \\\n",
      "1  The GeoSolutions technology will leverage Bene...   \n",
      "3  For the last quarter of 2010 , Componenta 's n...   \n",
      "4  According to the Finnish-Russian Chamber of Co...   \n",
      "5  The Swedish buyout firm has sold its remaining...   \n",
      "6    $SPY wouldn't be surprised to see a green close   \n",
      "\n",
      "                                      Processed Text  Word Count  \n",
      "1  geosolutions technology leverage benefon gps s...          21  \n",
      "3  last quarter componenta net sale double eur eu...          20  \n",
      "4  accord finnish russian chamber commerce major ...          11  \n",
      "5  swedish buyout firm sell remain percent stake ...          14  \n",
      "6                           surprise see green close           4  \n"
     ]
    }
   ],
   "source": [
    "# Check word count and filter\n",
    "df['word_count'] = df['processed_text'].apply(lambda x: len(str(x).split()))\n",
    "original_size = len(df)\n",
    "\n",
    "# Remove examples with less than 4 words\n",
    "df = df[df['word_count'] >= 4]\n",
    "\n",
    "print(f\"Original dataset size: {original_size}\")\n",
    "print(f\"Filtered dataset size: {len(df)}\")\n",
    "print(f\"Number of removed examples: {original_size - len(df)}\")\n",
    "\n",
    "# Display examples of processed texts with original for comparison\n",
    "df_comparison = pd.DataFrame({\n",
    "    'Original Text': df['text'],\n",
    "    'Processed Text': df['processed_text'],\n",
    "    'Word Count': df['word_count']\n",
    "})\n",
    "print(df_comparison.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdecb9f0",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "Perform the exact same train-test split as sentiment_analysis.ipynb for direct performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfca72e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4064\n",
      "Test set size: 1016\n",
      "\n",
      "Class distribution in test set:\n",
      "sentiment_encoded\n",
      "neutral     554\n",
      "positive    351\n",
      "negative    111\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'],  # Use raw text for LLM (no preprocessing needed)\n",
    "    df['sentiment_encoded'],\n",
    "    test_size=0.2, \n",
    "    random_state=9,  # Same random state as sentiment_analysis.ipynb\n",
    "    stratify=df['sentiment_encoded']\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "print(pd.Series(y_test).map({2: 'negative', 0: 'neutral', 1: 'positive'}).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c5b5e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set prepared for LLM evaluation\n",
      "Note: Training set (4064 samples) is not used for zero-shot LLM\n"
     ]
    }
   ],
   "source": [
    "# Create test dataframe for Gemini predictions\n",
    "df_test = pd.DataFrame({\n",
    "    'text': X_test.values,\n",
    "    'sentiment_encoded': y_test.values,\n",
    "    'sentiment': pd.Series(y_test.values).map({2: 'negative', 0: 'neutral', 1: 'positive'}).values\n",
    "})\n",
    "\n",
    "print(\"\\nTest set prepared for LLM evaluation\")\n",
    "print(f\"Note: Training set ({len(X_train)} samples) is not used for zero-shot LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7012301",
   "metadata": {},
   "source": [
    "## Note on Test Set Usage\n",
    "We will evaluate Gemini on the exact same test set as traditional ML models for fair comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043deda",
   "metadata": {},
   "source": [
    "## Google Gemini Flash 2.5 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3e6626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Google Gemini API configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Configure Google Gemini API\n",
    "# IMPORTANT: Set your API key as an environment variable or replace with your key\n",
    "# You can get your API key from: https://makersuite.google.com/app/apikey\n",
    "\n",
    "# Option 1: Set environment variable (recommended)\n",
    "# export GOOGLE_API_KEY='your-api-key-here'\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "# Option 2: Direct assignment (not recommended for production)\n",
    "# api_key = 'your-api-key-here'\n",
    "\n",
    "if not api_key:\n",
    "    print(\"⚠️ WARNING: GOOGLE_API_KEY not found!\")\n",
    "    print(\"Please set your API key:\")\n",
    "    print(\"  Option 1: Set environment variable GOOGLE_API_KEY\")\n",
    "    print(\"  Option 2: Uncomment and add your key in the cell above\")\n",
    "else:\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"✓ Google Gemini API configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "476fed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "print(\"Model initialized: gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f12fb4",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Gemini Flash 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c4e985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for sentiment analysis\n",
    "def create_sentiment_prompt(text):\n",
    "    \"\"\"\n",
    "    Create a prompt for Gemini to analyze sentiment of financial news.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Financial news text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted prompt for the LLM\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a financial sentiment analysis expert. Analyze the sentiment of the following financial news text and classify it into one of three categories: positive, negative, or neutral.\n",
    "\n",
    "Financial News Text:\n",
    "\"{text}\"\n",
    "\n",
    "Instructions:\n",
    "- Respond with ONLY ONE WORD: \"positive\", \"negative\", or \"neutral\"\n",
    "- Consider the financial context and implications\n",
    "- Do not provide explanations or additional text\n",
    "- Your response must be exactly one of these three words in lowercase\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08df3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment prediction from Gemini\n",
    "def predict_sentiment_gemini(text, model, max_retries=3):\n",
    "    \"\"\"\n",
    "    Predict sentiment using Google Gemini Flash 2.5.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text for sentiment analysis\n",
    "        model: Gemini model instance\n",
    "        max_retries (int): Maximum number of retry attempts\n",
    "        \n",
    "    Returns:\n",
    "        str: Predicted sentiment ('positive', 'negative', 'neutral') or 'error'\n",
    "    \"\"\"\n",
    "    prompt = create_sentiment_prompt(text)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            \n",
    "            # Extract and clean the response\n",
    "            sentiment = response.text.strip().lower()\n",
    "            \n",
    "            # Validate response\n",
    "            if sentiment in ['positive', 'negative', 'neutral']:\n",
    "                return sentiment\n",
    "            else:\n",
    "                # Try to extract valid sentiment from response\n",
    "                if 'positive' in sentiment:\n",
    "                    return 'positive'\n",
    "                elif 'negative' in sentiment:\n",
    "                    return 'negative'\n",
    "                elif 'neutral' in sentiment:\n",
    "                    return 'neutral'\n",
    "                else:\n",
    "                    print(f\"Invalid response: {sentiment}, retrying...\")\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)  # Wait before retry\n",
    "            else:\n",
    "                return 'error'\n",
    "    \n",
    "    return 'error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13349218",
   "metadata": {},
   "source": [
    "## Batch Prediction on Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99969fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0dc3a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running new predictions...\n"
     ]
    }
   ],
   "source": [
    "# Option to load previously saved predictions\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "predictions_file = '../data/gemini_predictions.pkl'\n",
    "\n",
    "# Set this to True to load saved predictions, False to run new predictions\n",
    "LOAD_SAVED_PREDICTIONS = False\n",
    "\n",
    "if LOAD_SAVED_PREDICTIONS and os.path.exists(predictions_file):\n",
    "    print(f\"Loading saved predictions from: {predictions_file}\")\n",
    "    df_test = pd.read_pickle(predictions_file)\n",
    "    print(f\"✓ Loaded {len(df_test)} predictions\")\n",
    "    print(\"\\nTo run new predictions, set LOAD_SAVED_PREDICTIONS = False\")\n",
    "else:\n",
    "    if LOAD_SAVED_PREDICTIONS and not os.path.exists(predictions_file):\n",
    "        print(f\"⚠️ Saved predictions file not found: {predictions_file}\")\n",
    "    print(\"Running new predictions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e191d045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 1016 texts from test set with Gemini Flash 2.5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▏        | 117/1016 [24:07<2:52:25, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on attempt 1: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 11.758415857s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 11\n",
      "}\n",
      "]\n",
      "Error on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 9.623785941s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 9\n",
      "}\n",
      "]\n",
      "Error on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 9.623785941s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 9\n",
      "}\n",
      "]\n",
      "Error on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 7.51393354s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "]\n",
      "Error on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 7.51393354s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▏        | 118/1016 [24:22<3:05:23, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on attempt 1: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 57.326810201s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "Error on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 55.207043228s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "]\n",
      "Error on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 55.207043228s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "]\n",
      "Error on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 53.036298444s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "]\n",
      "Error on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 53.036298444s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▏        | 119/1016 [24:36<3:14:20, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on attempt 1: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 42.896427128s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 42\n",
      "}\n",
      "]\n",
      "Error on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 40.76726942s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "]\n",
      "Error on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 40.76726942s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "]\n",
      "Error on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 38.608231153s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]\n",
      "Error on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 38.608231153s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▏        | 120/1016 [24:50<3:20:37, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on attempt 1: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 28.443945819s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Error on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 26.315126097s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "Error on attempt 2: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 26.315126097s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "Error on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 24.164768029s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "Error on attempt 3: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\n",
      "Please retry in 24.164768029s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 250\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▏        | 120/1016 [25:05<3:07:20, 12.55s/it]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m         errors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Rate limiting: sleep briefly between requests to avoid hitting rate limits\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust based on your API quota\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Add predictions to dataframe\u001b[39;00m\n\u001b[0;32m     20\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perform sentiment analysis on the entire test set (same as traditional ML evaluation)\n",
    "print(f\"Analyzing {len(df_test)} texts from test set with Gemini Flash 2.5...\")\n",
    "\n",
    "predictions = []\n",
    "errors = 0\n",
    "\n",
    "# Add progress bar\n",
    "for idx, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Processing\"):\n",
    "    text = row['text']\n",
    "    prediction = predict_sentiment_gemini(text, model)\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    if prediction == 'error':\n",
    "        errors += 1\n",
    "    \n",
    "    # Rate limiting: sleep briefly between requests to avoid hitting rate limits\n",
    "    time.sleep(10)  # Adjust based on your API quota\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df_test['gemini_prediction'] = predictions\n",
    "\n",
    "print(f\"\\n✓ Predictions completed!\")\n",
    "print(f\"Total predictions: {len(predictions)}\")\n",
    "print(f\"Errors: {errors}\")\n",
    "print(f\"Success rate: {((len(predictions) - errors) / len(predictions)) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to pickle file for future use\n",
    "import pickle\n",
    "\n",
    "predictions_file = '../data/gemini_predictions.pkl'\n",
    "df_test.to_pickle(predictions_file)\n",
    "print(f\"\\n✓ Predictions saved to: {predictions_file}\")\n",
    "print(f\"You can load this file later to skip the prediction step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows with prediction errors (if any)\n",
    "df_test_clean = df_test[df_test['gemini_prediction'] != 'error'].copy()\n",
    "print(f\"\\nSuccessfully predicted: {len(df_test_clean)} out of {len(df_test)} samples\")\n",
    "\n",
    "if errors > 0:    print(f\"⚠️ Warning: {errors} predictions failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91898982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Gemini predictions to numeric values for comparison\n",
    "df_test_clean['gemini_prediction_encoded'] = df_test_clean['gemini_prediction'].apply(encode_sentiment)\n",
    "\n",
    "# Map encoded values back to sentiment labels for display\n",
    "df_test_clean['sentiment'] = df_test_clean['sentiment_encoded'].map({2: 'negative', 0: 'neutral', 1: 'positive'})\n",
    "\n",
    "\n",
    "# Display sample resultsprint(df_test_clean[['text', 'sentiment', 'gemini_prediction']].head(10))\n",
    "print(\"\\nSample predictions:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d9706",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510beace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "y_true = df_test_clean['sentiment_encoded']\n",
    "y_pred = df_test_clean['gemini_prediction_encoded']\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GOOGLE GEMINI FLASH 2.5 PERFORMANCE METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"\\nTest Samples: {len(df_test_clean)}\")\n",
    "\n",
    "print(f\"Training Set Size: {len(X_train)} (not used for LLM)\")print(f\"Test Set Size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c497f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\")\n",
    "\n",
    "target_names = ['neutral', 'positive', 'negative']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=['neutral', 'positive', 'negative'],\n",
    "            yticklabels=['neutral', 'positive', 'negative'])\n",
    "plt.title('Confusion Matrix - Gemini Flash 2.5 Sentiment Analysis', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Sentiment', fontsize=12)\n",
    "plt.ylabel('True Sentiment', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454eb2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-CLASS ACCURACY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, label in enumerate(['neutral', 'positive', 'negative']):\n",
    "    mask = y_true == i\n",
    "    if mask.sum() > 0:\n",
    "        class_acc = accuracy_score(y_true[mask], y_pred[mask])\n",
    "        print(f\"\\n{label.capitalize()}:\")\n",
    "        print(f\"  Accuracy: {class_acc:.4f} ({class_acc*100:.2f}%)\")\n",
    "        print(f\"  Samples: {mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f40efe",
   "metadata": {},
   "source": [
    "## Prediction Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d889b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare actual vs predicted distributions\n",
    "comparison_data = pd.DataFrame({\n",
    "    'Category': ['Neutral', 'Positive', 'Negative'] * 2,\n",
    "    'Count': [\n",
    "        (y_true == 0).sum(), (y_true == 1).sum(), (y_true == 2).sum(),\n",
    "        (y_pred == 0).sum(), (y_pred == 1).sum(), (y_pred == 2).sum()\n",
    "    ],\n",
    "    'Type': ['Actual'] * 3 + ['Predicted'] * 3\n",
    "})\n",
    "\n",
    "fig = px.bar(comparison_data, \n",
    "             x='Category', \n",
    "             y='Count',\n",
    "             color='Type',\n",
    "             barmode='group',\n",
    "             title='Actual vs Predicted Sentiment Distribution',\n",
    "             color_discrete_map={'Actual': '#3498db', 'Predicted': '#e74c3c'})\n",
    "\n",
    "fig.update_layout(xaxis_title='Sentiment Category',\n",
    "                  yaxis_title='Count',\n",
    "                  title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7695d",
   "metadata": {},
   "source": [
    "## Sample Predictions Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some correct predictions\n",
    "print(\"=\"*70)\n",
    "print(\"SAMPLE CORRECT PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "correct_predictions = df_test_clean[df_test_clean['sentiment_encoded'] == df_test_clean['gemini_prediction_encoded']]\n",
    "print(f\"\\nShowing 5 random correct predictions (Total: {len(correct_predictions)}):\\n\")\n",
    "\n",
    "for idx, row in correct_predictions.sample(min(5, len(correct_predictions))).iterrows():\n",
    "    print(f\"Text: {row['text'][:100]}...\")\n",
    "    print(f\"True Sentiment: {row['sentiment']}\")\n",
    "    print(f\"Predicted Sentiment: {row['gemini_prediction']}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some incorrect predictions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE INCORRECT PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "incorrect_predictions = df_test_clean[df_test_clean['sentiment_encoded'] != df_test_clean['gemini_prediction_encoded']]\n",
    "print(f\"\\nShowing 5 random incorrect predictions (Total: {len(incorrect_predictions)}):\\n\")\n",
    "\n",
    "for idx, row in incorrect_predictions.sample(min(5, len(incorrect_predictions))).iterrows():\n",
    "    print(f\"Text: {row['text'][:100]}...\")\n",
    "    print(f\"True Sentiment: {row['sentiment']}\")\n",
    "    print(f\"Predicted Sentiment: {row['gemini_prediction']}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d46db6",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0214b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to file\n",
    "output_path = '../data/gemini_sentiment_predictions.csv'\n",
    "df_test_clean.to_csv(output_path, index=False)\n",
    "print(f\"✓ Results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n📊 Dataset Information:\")\n",
    "print(f\"   • Original dataset size: {len(df)}\")\n",
    "print(f\"   • Training set size: {len(X_train)} (not used for zero-shot LLM)\")\n",
    "print(f\"   • Test set size: {len(X_test)}\")\n",
    "print(f\"   • Test samples analyzed: {len(df_test_clean)}\")\n",
    "print(f\"   • Prediction errors: {errors}\")\n",
    "print(f\"   • Success rate: {((len(predictions) - errors) / len(predictions)) * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n🎯 Performance Metrics (on Test Set):\")\n",
    "print(f\"   • Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   • F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "print(f\"   • F1-Score (Macro): {f1_macro:.4f}\")\n",
    "\n",
    "print(f\"\\n✅ Correct Predictions: {len(correct_predictions)} ({len(correct_predictions)/len(df_test_clean)*100:.2f}%)\")\n",
    "\n",
    "print(f\"❌ Incorrect Predictions: {len(incorrect_predictions)} ({len(incorrect_predictions)/len(df_test_clean)*100:.2f}%)\")print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(\"   The model was not trained on the training set.\")\n",
    "print(\"\\n💡 Note: This is a zero-shot evaluation using Gemini Flash 2.5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
